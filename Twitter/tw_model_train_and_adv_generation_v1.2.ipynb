{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @authors: Raj Vardhan and Vaisakh S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from cleverhans.attacks import SaliencyMapMethod,FastGradientMethod,CarliniWagnerL2,DeepFool\n",
    "from cleverhans.utils import other_classes, set_log_level\n",
    "from cleverhans.utils import pair_visual, grid_visual, AccuracyReport\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils_tf import model_train, model_eval, model_argmax\n",
    "from cleverhans.utils_keras import KerasModelWrapper, cnn_model\n",
    "from cleverhans.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import pickle\n",
    "import operator\n",
    "from keras.models import Sequential\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data and model\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = 'adversary'\n",
    "dataset = 'twitter'\n",
    "attack_method = 'jsma'\n",
    "adversarial_examples_already_created = True\n",
    "target_type = 'target_next'\n",
    "\n",
    "directory = \"./twitter_data_new/\"\n",
    "model_dir = directory + \"model/\"\n",
    "model_name = 'model_twitter.h5'\n",
    "\n",
    "attack_directory = directory + role + '/' + dataset + '/' + target_type + '/' + attack_method + '/'\n",
    "\n",
    "##ATTACK METHOD SPECIFIC PARAMETERS\n",
    "# CW ATTACK METHOD\n",
    "CW_LEARNING_RATE = .2\n",
    "ATTACK_ITERATIONS = 100\n",
    "\n",
    "\n",
    "#JSMA\n",
    "THETA_JSMA = 0.09\n",
    "GAMMA_JSMA = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region 1: This code region is to be run for training the model. Move to next segment if model is already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# load datasets\n",
    "# file name can be passed as parameter\n",
    "df = pandas.read_csv(directory + \"honeypot.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_col = df.columns.size\n",
    "print('no. of columns is {}'.format(no_of_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df.values\n",
    "orig_X = ds[:,1:no_of_col].astype(float)\n",
    "orig_Y = ds[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(orig_X))\n",
    "X_unscaled = orig_X[indices]\n",
    "Y = orig_Y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be shuffled 0s and 1s\n",
    "Y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(directory + 'X_unscaled_shuffled.npy',X_unscaled)\n",
    "np.save(directory + 'Y_shuffled.npy',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Features #0 to #5 : \n",
    "0 - age \n",
    "1 - NumerOfFollowings \n",
    "2 - NumberOfFollowers \n",
    "3 - NumberOfTweets      [see description of feature #6 for difference]\n",
    "4 - LengthOfScreenName \n",
    "5 - LengthOfDescriptionInUserProfile\n",
    "\n",
    "Features #6 to #15: \n",
    "6 - num_tws         [smaller or equal than feature #3 as it depends on sampling period]\n",
    "7 - ratio_question\n",
    "8 - ratio_exclam\n",
    "9 - len_tws\n",
    "10 - speed_tws\n",
    "11 - num_url\n",
    "12 - ratio_url\n",
    "13 - num_at\n",
    "14 - ratio_at  [What's the ratio of tweets containing @; some samples have > 1; could be corrected]\n",
    "15 - num_RT\n",
    "\n",
    "Features #16 to #25: \n",
    "16 - ratio_RT\n",
    "17 - num_uniq_at\n",
    "18 - ratio_uniq_at\n",
    "19 - num_reply\n",
    "20 - ratio_reply\n",
    "21 - num_hash\n",
    "22 - ratio_hash\n",
    "23 - jacc_tw\n",
    "24 - jacc_url\n",
    "25 - compress_ratio\n",
    "\n",
    "Features #26-#27: \n",
    "26 - spam word ratio\n",
    "27 - FollowingChangeRatio\n",
    "\n",
    "There are total 6+10+10+2=28 features.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use previously shuffled data (don't shuffle every time)\n",
    "X_unscaled = np.load(directory + 'X_unscaled_shuffled.npy')\n",
    "Y = np.load(directory + 'Y_shuffled.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_categ = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train, test split\n",
    "x_train_unscaled, x_test_unscaled, y_train, y_test = train_test_split(X_unscaled,Y_categ,test_size=0.20, random_state=42, shuffle=True)\n",
    "\n",
    "# We will use this later for preparing the scaler object\n",
    "np.save(directory + \"x_train_unscaled.npy\", x_train_unscaled)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#sc = StandardScaler()\n",
    "sc = MinMaxScaler()\n",
    "x_train = sc.fit_transform(x_train_unscaled)\n",
    "x_test = sc.transform(x_test_unscaled)\n",
    "\n",
    "# save the scaled data\n",
    "np.save(directory+'x_train.npy',x_train)\n",
    "np.save(directory+'y_train.npy',y_train)\n",
    "\n",
    "np.save(directory+'x_test.npy',x_test)\n",
    "np.save(directory+'y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build DNNs\n",
    "DNNmodel = Sequential()\n",
    "DNNmodel.add(Dense(20, input_dim = no_of_col-1, kernel_initializer=\"uniform\",activation=\"relu\"))\n",
    "DNNmodel.add(Dropout(0.5))\n",
    "DNNmodel.add(Dense(20, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
    "DNNmodel.add(Dropout(0.5))\n",
    "DNNmodel.add(Dense(2))\n",
    "DNNmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "#compile Model\n",
    "DNNmodel.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# 3-fold validations\n",
    "history=DNNmodel.fit(x_train, y_train,validation_split=0.20,\n",
    "          epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "score = DNNmodel.evaluate(x_test, y_test, batch_size=256)\n",
    "print(\"Test Accuracy\",score)\n",
    "print(\"\\n%s: %.2f%%\" % (DNNmodel.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation through predict function\n",
    "\n",
    "y_pred = DNNmodel.predict(x_test)\n",
    "\n",
    "tp =0\n",
    "fp =0\n",
    "tn =0\n",
    "fn =0\n",
    "for i in range(len(y_pred)):\n",
    "    pred_class = np.argmax(y_pred[i])\n",
    "    true_class = np.argmax(y_test[i])\n",
    "    if(pred_class == true_class):\n",
    "        if true_class == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    else:\n",
    "        if true_class == 1:\n",
    "            fn += 1\n",
    "        else:\n",
    "            fp += 1        \n",
    "    \n",
    "precision = tp*100/ (tp+fp)\n",
    "recall = tp*100/ (tp+fn)\n",
    "acc = (tp+tn)*100/(tp+tn+fp+fn)\n",
    "\n",
    "total_actual_positives = tp+fn\n",
    "total_actual_negatives = fp+tn\n",
    "\n",
    "print(\"Accuracy is {}%\".format(acc))\n",
    "print('tp: {} fp: {} tn: {} fn:{} '.format(tp,fp,tn,fn))\n",
    "print(\"precision: {}%   recall: {}%\".format(precision, recall))\n",
    "\n",
    "print(\"Total true +ves: {} Total true -ves: {}\".format(total_actual_positives, total_actual_negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "DNNmodel.save(model_dir + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---x----- Region 1 ends ------x------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region 2 begins: Here we do adversarial attack generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model (Starting point)\n",
    "DNNmodel = load_model(model_dir + model_name)\n",
    "\n",
    "W = DNNmodel.get_weights()\n",
    "W={'weights1': W[0], \n",
    "   'weights2': W[2],\n",
    "   'weights3': W[4],\n",
    "   'biases1' : W[1],\n",
    "   'biases2' : W[3],    \n",
    "   'biases3' : W[5]    \n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading All Malicious Samples from pickle file\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "\n",
    "#Load stored data\n",
    "print('\\nLoading All Malicious Samples from pickle file')\n",
    "\n",
    "if role == 'adversary':\n",
    "    x_input = np.load(directory+'x_test.npy')\n",
    "    y_input = np.load(directory+'y_test.npy')\n",
    "elif role == 'defender':\n",
    "    x_input = np.load(directory+'x_train.npy')\n",
    "    y_input = np.load(directory+'y_train.npy')    \n",
    "    \n",
    "y_class = np.argmax(y_input, axis=1)\n",
    "ind_mal = np.where(y_class == 1)[0]\n",
    "\n",
    "x_mal = x_input[ind_mal]\n",
    "y_mal = np.ones(x_mal.shape[0])\n",
    "\n",
    "y_mal = to_categorical(y_mal)\n",
    "\n",
    "no_of_col = x_input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4447, 28)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if attack_method == 'jsma':\n",
    "    batch_size = 10\n",
    "else:\n",
    "    batch_size = 1\n",
    "    \n",
    "count = x_mal.shape[0] - x_mal.shape[0]%batch_size\n",
    "x_in = x_mal[:count,:]\n",
    "nb_features = x_in.shape[1]\n",
    "x_in_batch = x_in[:batch_size,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construction of tensorflow graph\n"
     ]
    }
   ],
   "source": [
    "print('\\nConstruction of tensorflow graph')\n",
    "#sess = tf.InteractiveSession()\n",
    "sess = tf.Session()\n",
    "##sess.run(tf.global_variables_initializer())\n",
    "x = tf.Variable(x_in_batch,dtype=tf.float32)\n",
    "\n",
    "### Construct Tensorlow Graph\n",
    "def model(x):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    with tf.variable_scope('mlp0',reuse=tf.AUTO_REUSE):\n",
    "        z = tf.layers.dense(x, units=20, \n",
    "                            activation=tf.nn.relu, \n",
    "                            kernel_initializer=tf.constant_initializer(W['weights1']), \n",
    "                            bias_initializer=tf.constant_initializer(W['biases1']) ) \n",
    "        # weight matrix automatically created by the model\n",
    "        \n",
    "        #z = tf.layers.dropout(z, rate=0.25, training=training) #Boolean variable training can\n",
    "                                                                #be set to false to avoid this step during inference\n",
    "\n",
    "    with tf.variable_scope('mlp1',reuse=tf.AUTO_REUSE):\n",
    "        z = tf.layers.dense(z, units=20, \n",
    "                            activation=tf.nn.relu, \n",
    "                            kernel_initializer=tf.constant_initializer(W['weights2']),\n",
    "                            bias_initializer=tf.constant_initializer(W['biases2']))\n",
    "        #z = tf.layers.dropout(z, rate=0.25, training=training)\n",
    "   \n",
    "    with tf.variable_scope('mlp2',reuse=tf.AUTO_REUSE):\n",
    "        logits = tf.layers.dense(z, units=2, \n",
    "                                 name='logits', \n",
    "                                 kernel_initializer=tf.constant_initializer(W['weights3']), \n",
    "                                 bias_initializer=tf.constant_initializer(W['biases3']))\n",
    "    #y = tf.nn.softmax(logits, name='ybar')\n",
    "\n",
    "    \n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell, we perform jsma attack on malware samples to convert them into benign (adversarial generation)\n",
    "one_hot_target = np.zeros((1, 2), dtype=np.float32)\n",
    "one_hot_target[0, 0] = 1  # NOTE: We do this to convert samples to benign \n",
    "                          # this is for generation of adversarial samples using cleverhans library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raj/anaconda2/envs/xai-env27/cleverhans/cleverhans/attacks.py:37: UserWarning: Argument back to attack constructors is not needed anymore and will be removed on or after 2019-03-26. All attacks are implemented using TensorFlow.\n",
      "  warnings.warn(\"Argument back to attack constructors is not needed\"\n"
     ]
    }
   ],
   "source": [
    "## NOTE: If you get an error in the next to next cell with jsma.generate_np method call, \n",
    "##       run sess.run(tf.global_variables_initializer()) again and then retry running that cell.\n",
    "\n",
    "#### Wrap the model as per cleverhans abstraction\n",
    "atdModel = CallableModelWrapper(model, 'logits')\n",
    "\n",
    "attack_obj = None\n",
    "\n",
    "if attack_method == 'jsma':\n",
    "    attack_obj = SaliencyMapMethod(atdModel, back='tf', sess=sess)\n",
    "elif attack_method == 'cwl2':\n",
    "    attack_obj = CarliniWagnerL2(atdModel, back='tf', sess=sess)\n",
    "    \n",
    "    cw_par = {'binary_search_steps': 1,\n",
    "          'max_iterations': ATTACK_ITERATIONS,\n",
    "          'learning_rate': CW_LEARNING_RATE,\n",
    "          'batch_size': 1,\n",
    "          'initial_const': 10}\n",
    "\n",
    "    cw_par['y_target'] = one_hot_target\n",
    "    \n",
    "else:\n",
    "    print('Unknown attack method')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of adv_x is (4440, 28)\n",
      "shape of y_class_adv is (4440,)\n",
      "attack succ rate is 70.11261261261261%\n"
     ]
    }
   ],
   "source": [
    "if not adversarial_examples_already_created:\n",
    "\n",
    "    startTime=datetime.datetime.now() \n",
    "\n",
    "    adv_x = np.zeros((count,x_in.shape[1]))\n",
    "    start = 0\n",
    "    end = batch_size\n",
    "    while end <= count:\n",
    "        print('batch {}'.format(end/batch_size))\n",
    "\n",
    "        if attack_method == 'jsma':\n",
    "            adv_x[start:end,:] = attack_obj.generate_np(x_in[start:end,:], theta = THETA_JSMA, gamma= GAMMA_JSMA, \n",
    "                       clip_min= 0., clip_max= 1.,y_target= one_hot_target)  # num_iterations = nb_features*gamma/2\n",
    "        elif attack_method == 'cwl2':\n",
    "            adv_x[start:end,:] = attack_obj.generate_np(x_in[start:end,:], **cw_par)\n",
    "\n",
    "        start = end\n",
    "        end = end + batch_size\n",
    "\n",
    "    endTime=datetime.datetime.now()\n",
    "    diffTime=endTime-startTime\n",
    "    print('Time taken: {}'.format(diffTime.total_seconds()))\n",
    "\n",
    "    # Save the adversarial examples\n",
    "    import os\n",
    "    if not os.path.exists(attack_directory):\n",
    "        os.makedirs(attack_directory)\n",
    "\n",
    "    print('saving adv examples to ', attack_directory)\n",
    "    np.save(attack_directory + '/xadvclev_twitter.npy', adv_x)\n",
    "    \n",
    "    x_adv = tf.placeholder(dtype=tf.float64, shape = (x_in.shape[0], nb_features) )\n",
    "\n",
    "    #find prediction logits (before softmax) for adversarial samples\n",
    "    pred = model(x_adv)\n",
    "    y_pred = tf.nn.softmax(pred)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #Find predictions on adv samples\n",
    "    y_pred_res_adv = sess.run(y_pred, feed_dict={x_adv:adv_x})\n",
    "    y_pred_res_sm_adv = np.argmax(y_pred_res_adv, axis=1)\n",
    "    y_pred_res_sm_adv\n",
    "\n",
    "    print('saving predictions on adv examples to ', attack_directory)\n",
    "    np.save(attack_directory + '/y_class_adv.npy', y_pred_res_sm_adv)\n",
    "    \n",
    "    attack_succ_rate = len(np.where(y_class_adv==0)[0])*100.0/len(y_class_adv)\n",
    "    print('attack success rate is {}%'.format(attack_succ_rate))\n",
    "    \n",
    "    # samples at which indices were able to fool the classifier i.e. have predicted class 0\n",
    "    ind_succ_on_target = np.where(y_class_adv == 0)[0]\n",
    "    np.save(attack_directory+'/ind_succ_on_target.npy',ind_succ_on_target)\n",
    "\n",
    "    print('saving attack success rate of adv examples to ', attack_directory)\n",
    "    np.save(attack_directory + '/attack_succ_rate.npy', attack_succ_rate)\n",
    "\n",
    "else:\n",
    "    adv_x = np.load(attack_directory + '/xadvclev_twitter.npy')\n",
    "    print('shape of adv_x is', adv_x.shape)\n",
    "    \n",
    "    y_class_adv = np.load(attack_directory + '/y_class_adv.npy')\n",
    "    print('shape of y_class_adv is', y_class_adv.shape)\n",
    "    \n",
    "    attack_succ_rate = np.load(attack_directory + '/attack_succ_rate.npy')\n",
    "    print('attack succ rate is {}%'.format(attack_succ_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some of the below analysis may only be valid for JSMA. For instance, CW or FGSM may make changes to all features compared to JSMA that just changes a few\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if attack_method == 'jsma':\n",
    "    theta = THETA_JSMA\n",
    "else:\n",
    "    theta = 0\n",
    "    \n",
    "count = x_in.shape[0]\n",
    "\n",
    "# Finding which features are changed across samples\n",
    "# diff [num_mal_samples X max_steps]\n",
    "step_max=x_in.shape[1]\n",
    "diff = np.full((count,step_max), -1)\n",
    "for i in range(0, count):\n",
    "    #print('i: {}'.format(i))\n",
    "    m = 0\n",
    "    d = dict()\n",
    "    x = np.where((abs(x_in[i] - adv_x[i]) > theta))[0]\n",
    "    if (len(x) > 0):\n",
    "        for k in range(0, len(x)):\n",
    "            if x[k] not in d:\n",
    "                diff[i,m]=x[k]\n",
    "                m+=1\n",
    "                d[x[k]]=1\n",
    "    else:\n",
    "        diff[i,0]=-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.36516583e-01, 1.56795186e-01, 4.13798193e-03, 1.10428503e-02,\n",
       "       7.33333333e-01, 3.35443038e-01, 1.00000000e+00, 2.00000000e-02,\n",
       "       1.00000000e-02, 5.47250616e-01, 5.40153090e-05, 2.10810811e-01,\n",
       "       2.10810811e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.21455850e-02,\n",
       "       9.69235751e-01, 4.43694007e-02, 4.25000000e-02, 1.20511444e-03])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 1.56795189e-01, 4.13798215e-03, 1.01042852e-01,\n",
       "       7.33333349e-01, 3.35443050e-01, 1.00000000e+00, 1.99999996e-02,\n",
       "       9.99999978e-03, 5.47250628e-01, 5.40153087e-05, 2.10810810e-01,\n",
       "       2.10810810e-01, 9.00000036e-02, 9.00000036e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 9.00000036e-02, 9.00000036e-02, 3.21455859e-02,\n",
       "       9.69235778e-01, 1.34369403e-01, 4.25000004e-02, 1.20511441e-03])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  3, 13, 14, 21, 22, 25, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [ 2,  3, 13, 14, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [ 2,  3, 13, 14, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [ 3, 14, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [ 3, 14, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [ 3, 14, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [ 0,  3, 13, 14, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [ 2,  3, 14, 19, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [ 3, 14, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [ 0,  2,  3, 13, 14, 16, 18, 21, 22, 23, 24, 25, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get the unscaled feature vectors by doing reverse ransform\n",
    "x_train_unscaled = np.load(directory+\"x_train_unscaled.npy\")\n",
    "\n",
    "#First prepare the sc object to be used for inverse transform\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#sc = StandardScaler()\n",
    "sc = MinMaxScaler()\n",
    "x_train = sc.fit_transform(x_train_unscaled)\n",
    "\n",
    "#Now that we have sc object, use it for inv transform\n",
    "# Unscaled adversarial samples\n",
    "x_adv_inv_scale = sc.inverse_transform(adv_x)\n",
    "\n",
    "# Unscaled original malicious samples\n",
    "x_in_inv_scale = sc.inverse_transform(x_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Changes for sample 0 are as follows----\n",
      "feature 0\n",
      "changed from 38656417.0 to 114872250.0\n",
      "\n",
      "feature 3\n",
      "changed from 3870.0000000000005 to 35410.77054385841\n",
      "\n",
      "feature 13\n",
      "changed from 0.0 to 125.55000498890877\n",
      "\n",
      "feature 14\n",
      "changed from 0.0 to 0.6408725086874608\n",
      "\n",
      "feature 21\n",
      "changed from 0.0 to 108.00000429153442\n",
      "\n",
      "feature 22\n",
      "changed from 0.0 to 0.7309923954592407\n",
      "\n",
      "feature 25\n",
      "changed from 0.2514266036993309 to 0.7614266177018482\n",
      "\n",
      "----Changes for sample 1 are as follows----\n",
      "feature 2\n",
      "changed from 6993.0 to 394834.2440955788\n",
      "\n",
      "feature 3\n",
      "changed from 1992.0 to 33532.770738355815\n",
      "\n",
      "feature 13\n",
      "changed from 0.0 to 125.55000498890877\n",
      "\n",
      "feature 14\n",
      "changed from 0.0 to 0.6408725086874608\n",
      "\n",
      "----Changes for sample 2 are as follows----\n",
      "feature 2\n",
      "changed from 221.0 to 388062.2388363853\n",
      "\n",
      "feature 3\n",
      "changed from 427.0 to 31967.771335616708\n",
      "\n",
      "feature 13\n",
      "changed from 0.0 to 125.55000498890877\n",
      "\n",
      "feature 14\n",
      "changed from 0.0 to 0.6408725086874608\n",
      "\n",
      "----Changes for sample 3 are as follows----\n",
      "feature 3\n",
      "changed from 625.0 to 32165.772015847266\n",
      "\n",
      "feature 14\n",
      "changed from 0.0 to 0.6408725086874608\n",
      "\n",
      "----Changes for sample 4 are as follows----\n",
      "feature 3\n",
      "changed from 18.0 to 31558.772027269006\n",
      "\n",
      "feature 14\n",
      "changed from 0.0 to 0.6408725086874608\n",
      "\n",
      "----Changes for sample 5 are as follows----\n",
      "feature 3\n",
      "changed from 11.0 to 31551.7717262879\n",
      "\n",
      "feature 14\n",
      "changed from 0.0 to 0.6408725086874608\n",
      "\n",
      "----Changes for sample 6 are as follows----\n",
      "feature 0\n",
      "changed from 500021.0 to 114872250.0\n",
      "\n",
      "feature 3\n",
      "changed from 1.0 to 31541.771296314895\n",
      "\n",
      "feature 13\n",
      "changed from 0.0 to 125.55000498890877\n",
      "\n",
      "feature 14\n",
      "changed from 0.0 to 0.6408725086874608\n",
      "\n",
      "----Changes for sample 7 are as follows----\n",
      "feature 2\n",
      "changed from 392.0 to 388233.2414488122\n",
      "\n",
      "feature 3\n",
      "changed from 0.0 to 31540.771253317595\n",
      "\n",
      "feature 14\n",
      "changed from 0.0 to 0.6408725086874608\n",
      "\n",
      "feature 19\n",
      "changed from 0.0 to 12.060000479221344\n",
      "\n",
      "----Changes for sample 8 are as follows----\n",
      "feature 3\n",
      "changed from 48.00000000000001 to 31588.770706109703\n",
      "\n",
      "feature 14\n",
      "changed from 0.0 to 0.6408725086874608\n",
      "\n",
      "----Changes for sample 9 are as follows----\n",
      "feature 0\n",
      "changed from 138843.0 to 20815849.370140582\n",
      "\n",
      "feature 2\n",
      "changed from 11.0 to 387852.2581594661\n",
      "\n",
      "feature 3\n",
      "changed from 46.0 to 31586.7706201151\n",
      "\n",
      "feature 13\n",
      "changed from 0.0 to 125.55000498890877\n",
      "\n",
      "feature 14\n",
      "changed from 0.0 to 0.6408725086874608\n",
      "\n",
      "feature 16\n",
      "changed from 0.0 to 0.194400007724762\n",
      "\n",
      "feature 18\n",
      "changed from 0.0 to 0.6203355951197196\n",
      "\n",
      "feature 21\n",
      "changed from 2.0 to 110.00000238418579\n",
      "\n",
      "feature 22\n",
      "changed from 0.04347826086956521 to 0.7744706509677508\n",
      "\n",
      "feature 23\n",
      "changed from 0.007658749107783245 to 0.09765875339508057\n",
      "\n",
      "feature 24\n",
      "changed from 0.0 to 0.09000000357627869\n",
      "\n",
      "feature 25\n",
      "changed from 0.5908440629470673 to 1.1008440802494683\n",
      "\n",
      "----Changes for sample 10 are as follows----\n",
      "feature 3\n",
      "changed from 0.0 to 31540.771253317595\n",
      "\n",
      "feature 14\n",
      "changed from 0.0 to 0.6408725086874608\n",
      "\n",
      "----Changes for sample 11 are as follows----\n",
      "feature 2\n",
      "changed from 467.0 to 388308.24372117966\n",
      "\n",
      "feature 5\n",
      "changed from 87.0 to 129.66000366210938\n",
      "\n",
      "feature 9\n",
      "changed from 57.37931034482759 to 68.5172608485818\n",
      "\n",
      "feature 12\n",
      "changed from 0.4137931034482759 to 0.8300431109964848\n",
      "\n",
      "feature 13\n",
      "changed from 12.0 to 137.5500039383769\n",
      "\n",
      "feature 15\n",
      "changed from 1.0 to 39.880000948905945\n",
      "\n",
      "feature 19\n",
      "changed from 0.0 to 12.060000479221344\n",
      "\n",
      "feature 21\n",
      "changed from 0.0 to 108.00000429153442\n",
      "\n",
      "feature 22\n",
      "changed from 0.0 to 0.7309923954592407\n",
      "\n",
      "feature 24\n",
      "changed from 0.10606060606060606 to 0.19606061279773712\n",
      "\n",
      "----Changes for sample 12 are as follows----\n",
      "feature 0\n",
      "changed from 16629805.0 to 99337828.5934478\n",
      "\n",
      "feature 2\n",
      "changed from 382.0 to 388223.2561291605\n",
      "\n",
      "feature 3\n",
      "changed from 891.0 to 32431.770397737622\n",
      "\n",
      "feature 13\n",
      "changed from 0.0 to 125.55000498890877\n",
      "\n",
      "feature 14\n",
      "changed from 0.0 to 0.6408725086874608\n",
      "\n",
      "feature 16\n",
      "changed from 0.01 to 0.2044000017642975\n",
      "\n",
      "feature 21\n",
      "changed from 102.0 to 210.00001430511475\n",
      "\n",
      "----Changes for sample 13 are as follows----\n",
      "feature 0\n",
      "changed from 7955085.0 to 69986104.2200625\n",
      "\n",
      "feature 3\n",
      "changed from 1375.0 to 32915.77031980455\n",
      "\n",
      "feature 13\n",
      "changed from 194.99999999999997 to 320.55000610649586\n",
      "\n",
      "feature 14\n",
      "changed from 0.9749999999999999 to 1.6158725277289445\n",
      "\n",
      "feature 15\n",
      "changed from 1.0 to 39.880000948905945\n",
      "\n",
      "feature 21\n",
      "changed from 145.0 to 253.00000905990598\n",
      "\n",
      "feature 22\n",
      "changed from 0.7249999999999999 to 1.4559923892712776\n",
      "\n",
      "feature 23\n",
      "changed from 0.2911033932912606 to 0.38110339641571045\n",
      "\n",
      "feature 25\n",
      "changed from 0.11566643405443128 to 0.6256664469838141\n",
      "\n",
      "----Changes for sample 14 are as follows----\n",
      "feature 2\n",
      "changed from 0.0 to 387841.2454114258\n",
      "\n",
      "feature 3\n",
      "changed from 3.0000000000000004 to 31543.771382309496\n",
      "\n",
      "----Changes for sample 15 are as follows----\n",
      "feature 0\n",
      "changed from 2476805.0 to 23153810.537919402\n",
      "\n",
      "feature 2\n",
      "changed from 13.0 to 387854.248801969\n",
      "\n",
      "feature 3\n",
      "changed from 11.0 to 31551.7717262879\n",
      "\n",
      "----Changes for sample 16 are as follows----\n",
      "feature 2\n",
      "changed from 787.0 to 388628.25555709004\n",
      "\n",
      "feature 3\n",
      "changed from 20.0 to 31560.772113263607\n",
      "\n",
      "feature 13\n",
      "changed from 0.0 to 125.55000498890877\n",
      "\n",
      "feature 14\n",
      "changed from 0.0 to 0.6408725086874608\n",
      "\n",
      "----Changes for sample 17 are as follows----\n",
      "feature 0\n",
      "changed from 33572284.0 to 95603299.51174557\n",
      "\n",
      "feature 2\n",
      "changed from 7804.0 to 395645.2382726893\n",
      "\n",
      "feature 3\n",
      "changed from 24340.0 to 55880.77337628603\n",
      "\n",
      "feature 6\n",
      "changed from 175.0 to 193.00000667572021\n",
      "\n",
      "feature 8\n",
      "changed from 0.017142857142857144 to 0.1071428582072258\n",
      "\n",
      "feature 13\n",
      "changed from 4.0 to 129.55000810325146\n",
      "\n",
      "feature 14\n",
      "changed from 0.022857142857142857 to 0.6637296622131493\n",
      "\n",
      "feature 16\n",
      "changed from 0.005714285714285713 to 0.2001142877340317\n",
      "\n",
      "feature 21\n",
      "changed from 1.0 to 109.00000333786011\n",
      "\n",
      "feature 22\n",
      "changed from 0.005714285714285713 to 0.7367066718239821\n",
      "\n",
      "feature 25\n",
      "changed from 0.3787708759654103 to 0.8887709577878314\n",
      "\n",
      "----Changes for sample 18 are as follows----\n",
      "feature 2\n",
      "changed from 122.0 to 387963.25253257155\n",
      "\n",
      "feature 3\n",
      "changed from 535.0 to 32075.77075716853\n",
      "\n",
      "----Changes for sample 19 are as follows----\n",
      "feature 3\n",
      "changed from 32.0 to 31572.770018152893\n",
      "\n",
      "feature 13\n",
      "changed from 1.0 to 126.55000057071447\n",
      "\n",
      "feature 14\n",
      "changed from 0.03125 to 0.6721225079374025\n",
      "\n",
      "feature 15\n",
      "changed from 0.0 to 38.88000154495239\n",
      "\n",
      "feature 19\n",
      "changed from 0.0 to 12.060000479221344\n",
      "\n",
      "feature 25\n",
      "changed from 0.5421577515865821 to 1.0521577994028726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the changes in features between malicious and adversarial samples\n",
    "for i in range(20):\n",
    "    \n",
    "    print('----Changes for sample {} are as follows----'.format(i))\n",
    "    for c in range(no_of_col):\n",
    "        if diff[i,c] < 0:\n",
    "            break\n",
    "        print('feature {}'.format(diff[i,c]))\n",
    "        print('changed from {} to {}\\n'.format( x_in_inv_scale[i, diff[i,c]], x_adv_inv_scale[i, diff[i,c]]))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_unscaled = np.load(directory + \"x_train_unscaled.npy\")\n",
    "y_train = np.load(directory + \"y_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.16435760e+07, 7.69200000e+03, 6.99300000e+03, 1.99200000e+03,\n",
       "       1.50000000e+01, 1.55000000e+02, 2.00000000e+02, 4.00000000e-02,\n",
       "       6.00000000e-02, 4.59750000e+01, 1.22995802e+01, 1.99000000e+02,\n",
       "       9.95000000e-01, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "       5.00000000e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.00000000e+00, 5.00000000e-03, 9.67283609e-03,\n",
       "       9.69853931e-01, 4.17164329e-01, 1.15000000e-01, 2.71579562e+00])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in_inv_scale[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Features #0 to #5 : \n",
    "0 - age \n",
    "1 - NumerOfFollowings \n",
    "2 - NumberOfFollowers \n",
    "3 - NumberOfTweets      [see description of feature #6 for difference]\n",
    "4 - LengthOfScreenName \n",
    "5 - LengthOfDescriptionInUserProfile\n",
    "\n",
    "Features #6 to #15: \n",
    "6 - num_tws         [smaller or equal than feature #3 as it depends on sampling period]\n",
    "7 - ratio_question\n",
    "8 - ratio_exclam\n",
    "9 - len_tws\n",
    "10 - speed_tws\n",
    "11 - num_url\n",
    "12 - ratio_url\n",
    "13 - num_at\n",
    "14 - ratio_at  [What's the ratio of tweets containing @; some samples have > 1; could be corrected]\n",
    "15 - num_RT\n",
    "\n",
    "Features #16 to #25: \n",
    "16 - ratio_RT\n",
    "17 - num_uniq_at\n",
    "18 - ratio_uniq_at\n",
    "19 - num_reply\n",
    "20 - ratio_reply\n",
    "21 - num_hash\n",
    "22 - ratio_hash\n",
    "23 - jacc_tw\n",
    "24 - jacc_url\n",
    "25 - compress_ratio\n",
    "\n",
    "Features #26-#27: \n",
    "26 - spam word ratio\n",
    "27 - FollowingChangeRatio\n",
    "\n",
    "There are total 6+10+10+2=28 features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python xaienv",
   "language": "python",
   "name": "xai-env27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
